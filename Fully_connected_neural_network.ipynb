{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24859900667754298"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_prime(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0,X)\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def relu_prime(X):\n",
    "    return np.array([1 if x >= 0 else 0 for x in X])\n",
    "\n",
    "def activation(name):\n",
    "    if name =='sigmoid':\n",
    "        return sigmoid,sigmoid_prime\n",
    "    elif name=='relu':\n",
    "        return relu,relu_prime\n",
    "    else:\n",
    "        raise Exception('activation function not in [sigmoid,relu]')\n",
    "        \n",
    "def mean_square_error(y_hat,y):\n",
    "    return np.square(y_hat - y).mean(axis = 1)\n",
    "\n",
    "def mean_square_error_der(y_hat,y):\n",
    "    if len(y) > 1:\n",
    "        return 2*(y_hat - y).mean(axis = 1)\n",
    "    else:\n",
    "        return 2*(y_hat - y)\n",
    "\n",
    "def square_sum(X):\n",
    "    return np.square(X).sum()\n",
    "\n",
    "def loss_function(name):\n",
    "    if name=='mean_square_error':\n",
    "        return mean_square_error , mean_square_error_der\n",
    "    else:\n",
    "        raise Exception('loss function not in [mean_square_error]')\n",
    "\n",
    "def penalization(name):\n",
    "    if name == 'square_sum':\n",
    "        return square_sum\n",
    "    else:\n",
    "        raise Exception('penalization function not in [square_sum]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,layers_parameters , global_parameters):\n",
    "        self.layers = {l:{'W' : 0.1*np.random.random(size = (layers[l]['output_dim'],layers[l]['input_dim'])),\n",
    "                          'B' : 0.1*np.random.random(size = (layers[l]['output_dim'],1)),\n",
    "                          'g' : activation(layers[l]['activation'])[0],\n",
    "                          'g_prime': activation(layers[l]['activation'])[1],\n",
    "                          'shape':{'W':(layers[l]['output_dim'],layers[l]['input_dim']),\n",
    "                                   'B':(layers[l]['output_dim'],1),\n",
    "                                   'g_prime':(layers[l]['output_dim'],1),\n",
    "                                   'input':(layers[l]['input_dim'],1),\n",
    "                                   'output':(layers[l]['output_dim'],1)}\n",
    "                         } for l in layers}\n",
    "        \n",
    "        self.input_dim = global_parameters['input']\n",
    "        self.output_dim = global_parameters['output']\n",
    "        self.layers_dim = global_parameters['layers']\n",
    "        self.batch_size = global_parameters['batch']\n",
    "        self.lr = global_parameters['learning_rate']\n",
    "        \n",
    "        self.loss = loss_function(global_parameters['loss'])[0]\n",
    "        self.loss_der = loss_function(global_parameters['loss'])[1]\n",
    "        \n",
    "    def predict(self,X):\n",
    "        if len(X) != self.input_dim:\n",
    "            raise Exception('input of size {} instead of {}'.format(len(X),self.input_dim))\n",
    "        intermediary_step = self.forward(X)\n",
    "        return intermediary_step[-1][2]\n",
    "    \n",
    "    def loss_calculation(self,x,y):\n",
    "        y_hat = self.predict(X)\n",
    "        return self.loss(y_hat,h)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        intermediary_step = []\n",
    "        if len(x) != self.input_dim:\n",
    "            raise Exception('input of size {} instead of {}'.format(len(x),self.input_dim))\n",
    "        x = x.reshape((self.input_dim,1))\n",
    "        for n in range(self.layers_dim):\n",
    "            z = np.dot(self.layers[n]['W'] , x) + self.layers[n]['B']\n",
    "            z = z.reshape(self.layers[n]['shape']['output'])\n",
    "            h = self.layers[n]['g'](z).reshape(self.layers[n]['shape']['output'])\n",
    "            x = x.reshape(self.layers[n]['shape']['input'])\n",
    "            intermediary_step.append([x , z , h])\n",
    "            x = np.array(h)\n",
    "            \n",
    "        return intermediary_step\n",
    "    \n",
    "    def backward(self , intermediary_step , y):\n",
    "        if len(intermediary_step) != self.layers_dim:\n",
    "            raise Exception('dimensions do not match')\n",
    "        dJ_dh = self.loss_der(intermediary_step[-1][2] , y.reshape((2,1)))\n",
    "        dJ_dh.reshape((self.output_dim , 1))\n",
    "        for i in range(len(intermediary_step)):\n",
    "            k = len(intermediary_step) - i - 1\n",
    "            x , z , h = intermediary_step[k]\n",
    "            n , m = self.layers[k]['shape']['output'] , self.layers[k]['shape']['input']\n",
    "            if x.shape != m or z.shape != n or h.shape != n:\n",
    "                x.reshape(m)\n",
    "                z.reshape(n)\n",
    "                h.reshape(n)\n",
    "            dJ_dz = dJ_dh * self.layers[k]['g_prime'](z)\n",
    "            if dJ_dz.shape != n:\n",
    "                dJ_dz = dJ_dz.reshape(n)\n",
    "            dJ_dw = np.dot(dJ_dz,x.T)\n",
    "            dJ_db = dJ_dz\n",
    "            dJ_dh = np.dot(self.layers[k]['W'].T,dJ_dz)\n",
    "            self.layers[k]['W'] = self.layers[k]['W'] - self.lr * dJ_dw\n",
    "            self.layers[k]['B'] = self.layers[k]['B'] - self.lr * dJ_db\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def train(self , X , Y):\n",
    "        if len(X) != len(Y):\n",
    "            raise Exception('X and Y dimension do not match')\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            print(i,end = '\\r')\n",
    "            x , y = X[i] , Y[i]\n",
    "            intermediary_step = self.forward(x)\n",
    "            self.backward(intermediary_step,np.array([y]))  \n",
    "        return self.score(X,Y)\n",
    "    \n",
    "    def score(self,X,Y):\n",
    "        mean_square = 0\n",
    "        for i in range(len(X)):\n",
    "            y = self.predict(X[i])\n",
    "            mean_square += np.square(y - Y[i])\n",
    "        return np.sqrt(mean_square.mean())/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {\n",
    "          0:{'input_dim' : 2,\n",
    "             'output_dim': 3,\n",
    "             'activation': 'sigmoid'},\n",
    "          1:{'input_dim' : 3,\n",
    "             'output_dim': 2,\n",
    "             'activation': 'relu'}\n",
    "         }\n",
    "\n",
    "parameters = {'input': 2,\n",
    "              'output' : 2,\n",
    "              'layers': 2,\n",
    "              'loss': 'mean_square_error',\n",
    "              'penalization':'square_sum',\n",
    "              'batch':1,\n",
    "              'learning_rate':0.1}\n",
    "\n",
    "nn = NeuralNetwork(layers , parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for i in range(10000):\n",
    "#     y = i%2\n",
    "#     dist = np.random.normal(loc = 1 + i%2,scale = 0.2)\n",
    "#     x0 = np.random.uniform(low = -np.sqrt(dist/2),high = np.sqrt(dist/2))\n",
    "#     sign = -1 if np.random.random() > 0.5 else 1\n",
    "#     x1 = sign*np.sqrt(dist - x0**2)\n",
    "#     data.append([x0,x1,y])\n",
    "# X = np.array(data)[:,:2]\n",
    "# Y = np.array(data)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(100000):\n",
    "    x , y = np.random.random() , np.random.random()\n",
    "    norme = np.square(x ** 2 + y ** 2)\n",
    "    angle = math.atan(y/x)\n",
    "    data.append([x,y,norme,angle])\n",
    "X = np.array(data)[:,:2]\n",
    "Y = np.array(data)[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017984188139190441"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74999\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002075081946097534"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(X[:75000],Y[:75000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002075081946097534, 0.0036048963836632646)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X[:75000],Y[:75000]),nn.score(X[75000:],Y[75000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       ],\n",
       "       [0.5868795]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(0,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.154593 ],\n",
       "       [0.5868795]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([max(0,x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.dot(nn.layers[0]['W'] , X[0].reshape(2,1)) + nn.layers[0]['B']\n",
    "z = z.reshape(nn.layers[0]['shape']['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0].reshape((2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([0.13445301]), array([1.24396206])],\n",
       "       [array([0.54997813]), array([1.73574006])],\n",
       "       [array([-1.0244631]), array([0.7470272])]], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.layers[0]['W']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "h = nn.layers[0]['g'](z).reshape(nn.layers[0]['shape']['output'])\n",
    "x = x.reshape(nn.layers[0]['shape']['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73105858],\n",
       "       [0.88079708]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.layers[0]['g'](np.array([1,2]).reshape(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
